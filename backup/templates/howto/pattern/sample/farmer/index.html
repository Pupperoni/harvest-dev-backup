<div class="row-fluid" >
    <div class="span8">

        <p>1. Identify the target website and check the type of website. Is it Aggregate or Specific?</p>
<pre>
</pre>
        <p>2. Create pattern under <code>{PROJECT_ROOT}/modules/farmers/</code>. Format: <code>(domain).py</code></p>

        <p>3. Import abstract library Farmer. Note: I'm using abstract class design implementation.</p>
<pre>
import logging
log = logging.getLogger(__name__)

from lib.main.common.abstracts import Farmer
</pre>

        <p>4. Set the pattern details.</p>
<pre>
class ClastName(Farmer):
    # Results dict key value / exception handling / logging name
    name = "&lt;name&gt;"  # Name of the site
    authors = ["&lt;author&gt;"]  # name of devs who created or updated the pattern
    categories = ["&lt;category&gt;"]  # service offered by the site (check AC master list)
    date_created = "&lt;date&gt;"  # date created or last update
    enabled = &lt;enabled&gt;  # enable this farmer
    frequency = &lt;frequency&gt;  # site's update frequency in minutes
    priority = &lt;priority&gt;  # priority of the site upon processing
    sleep_ceiling = &lt;sleep_ceiling&gt;  # max sleep for this farmer
    tags = ["&lt;tags&gt;"]
    max_page = &lt;max_page&gt;

    start_urls = ["&lt;url&gt;"]

    metadata_xpath = {
        'version': ""
    }

    identifier_xpath = {
        'id': ""
    }
</pre>
        <p>5. Set the pattern key. For the Harvest processing module to evaluate the output of the pattern.</p>
<pre>
    def run(self):
        self.key = "&lt;name&gt;"
        log.info("&lt;Debugging logs here&gt;")
</pre>

        <p>5.1 For Aggregate websites we manipulate the start URL so we can crawl the website from page 1 to N.</p>
<pre id="farmer_pattern">
    """For Aggregate website"""

    def run(self):
        self.key = "majorgeeks"
        log.info("Farming MajorGeeks Website")

        self.data = []
        for page in range(1, self.max_page + 1):
            url = self.start_urls[0].format(page)
            log.info("Accessing {}".format(url))

            # Pattern logic here
</pre>

        <ul class="tm-nav tm-nav-list tm-nav-nested-list">
            <li>
                <a href="#" data-toggle="tm-nav-nested-list" class="collapsed">See pattern here<span class="caret"></span></a>
                <ul class="tm-nav tm-nav-list collapse">
                    <li>

<pre class="prettyprint">
import logging
log = logging.getLogger(__name__)

from lib.main.common.abstracts import Farmer

class ClastName(Farmer):
    # Results dict key value / exception handling / logging name
    name = "&lt;name&gt;"  # Name of the site
    authors = ["&lt;author&gt;"]  # name of devs who created or updated the pattern
    categories = ["&lt;category&gt;"]  # service offered by the site (check AC master list)
    date_created = "&lt;date&gt;"  # date created or last update
    enabled = &lt;enabled&gt;  # enable this farmer
    frequency = &lt;frequency&gt;  # site's update frequency in minutes
    priority = &lt;priority&gt;  # priority of the site upon processing
    sleep_ceiling = &lt;sleep_ceiling&gt;  # max sleep for this farmer
    tags = ["&lt;tags&gt;"]
    max_page = &lt;max_page&gt;

    start_urls = ["&lt;url&gt;"]

    metadata_xpath = {
        'version': ""
    }

    identifier_xpath = {
        'id': ""
    }

    def run(self):
        self.key = "majorgeeks"
        log.info("Farming MajorGeeks Website")

        self.data = []
        for page in range(1, self.max_page + 1):
            url = self.start_urls[0].format(page)
            log.info("Accessing {}".format(url))

            # Pattern logic here

            #    Go to page
            ##   Extract product URLS
            ###  Extract metadata

        # Return the data to Harvest processing.
        return self.data
</pre>

                    </li>
                </ul>
            </li>
        </ul>

    </div>

    <div class="span4">
    </div>
</div>